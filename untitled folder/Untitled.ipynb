{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a25f90a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in /Users/admin/miniconda3/lib/python3.9/site-packages (1.4.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3fabd083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting utils\n",
      "  Downloading utils-1.0.1-py2.py3-none-any.whl (21 kB)\n",
      "Installing collected packages: utils\n",
      "Successfully installed utils-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "db7de279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "3698f1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "b41f8c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext,SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "e0aaeced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://admins-mbp:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc=SparkContext.getOrCreate()\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "837a18cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "8d4b31e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('/Users/admin/Downloads/ProjetTD-AC-main/data/DS1/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "bfdaa8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Object</th>\n",
       "      <th>Property</th>\n",
       "      <th>Value</th>\n",
       "      <th>Source</th>\n",
       "      <th>ObjectProperty</th>\n",
       "      <th>trustworthiness</th>\n",
       "      <th>oldtrustworthiness</th>\n",
       "      <th>Value_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Object1</td>\n",
       "      <td>Property5</td>\n",
       "      <td>234041</td>\n",
       "      <td>Source1</td>\n",
       "      <td>Object1Property5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Object1</td>\n",
       "      <td>Property3</td>\n",
       "      <td>476627</td>\n",
       "      <td>Source1</td>\n",
       "      <td>Object1Property3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Object2</td>\n",
       "      <td>Property5</td>\n",
       "      <td>360789</td>\n",
       "      <td>Source1</td>\n",
       "      <td>Object2Property5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Object2</td>\n",
       "      <td>Property3</td>\n",
       "      <td>217264</td>\n",
       "      <td>Source1</td>\n",
       "      <td>Object2Property3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Object3</td>\n",
       "      <td>Property5</td>\n",
       "      <td>274376</td>\n",
       "      <td>Source1</td>\n",
       "      <td>Object3Property5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Object996</td>\n",
       "      <td>Property1</td>\n",
       "      <td>978533</td>\n",
       "      <td>Source8</td>\n",
       "      <td>Object996Property1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Object997</td>\n",
       "      <td>Property1</td>\n",
       "      <td>591492</td>\n",
       "      <td>Source8</td>\n",
       "      <td>Object997Property1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Object998</td>\n",
       "      <td>Property1</td>\n",
       "      <td>542462</td>\n",
       "      <td>Source8</td>\n",
       "      <td>Object998Property1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Object999</td>\n",
       "      <td>Property1</td>\n",
       "      <td>983588</td>\n",
       "      <td>Source8</td>\n",
       "      <td>Object999Property1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Object1000</td>\n",
       "      <td>Property1</td>\n",
       "      <td>964731</td>\n",
       "      <td>Source8</td>\n",
       "      <td>Object1000Property1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID      Object   Property   Value   Source       ObjectProperty  \\\n",
       "0      0.0     Object1  Property5  234041  Source1     Object1Property5   \n",
       "1      0.0     Object1  Property3  476627  Source1     Object1Property3   \n",
       "2      0.0     Object2  Property5  360789  Source1     Object2Property5   \n",
       "3      0.0     Object2  Property3  217264  Source1     Object2Property3   \n",
       "4      0.0     Object3  Property5  274376  Source1     Object3Property5   \n",
       "...    ...         ...        ...     ...      ...                  ...   \n",
       "59995  0.0   Object996  Property1  978533  Source8   Object996Property1   \n",
       "59996  0.0   Object997  Property1  591492  Source8   Object997Property1   \n",
       "59997  0.0   Object998  Property1  542462  Source8   Object998Property1   \n",
       "59998  0.0   Object999  Property1  983588  Source8   Object999Property1   \n",
       "59999  0.0  Object1000  Property1  964731  Source8  Object1000Property1   \n",
       "\n",
       "       trustworthiness  oldtrustworthiness  Value_confidence  \n",
       "0                  0.8                 0.8               1.0  \n",
       "1                  0.8                 0.8               1.0  \n",
       "2                  0.8                 0.8               1.0  \n",
       "3                  0.8                 0.8               1.0  \n",
       "4                  0.8                 0.8               1.0  \n",
       "...                ...                 ...               ...  \n",
       "59995              0.8                 0.8               0.0  \n",
       "59996              0.8                 0.8               0.0  \n",
       "59997              0.8                 0.8               0.0  \n",
       "59998              0.8                 0.8               0.0  \n",
       "59999              0.8                 0.8               0.0  \n",
       "\n",
       "[60000 rows x 9 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "d03a6979",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_=pd.DataFrame(data, columns= ['Object','Property','Value','Source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "79fb647d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Object</th>\n",
       "      <th>Property</th>\n",
       "      <th>Value</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Object1</td>\n",
       "      <td>Property5</td>\n",
       "      <td>234041</td>\n",
       "      <td>Source1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Object1</td>\n",
       "      <td>Property3</td>\n",
       "      <td>476627</td>\n",
       "      <td>Source1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Object2</td>\n",
       "      <td>Property5</td>\n",
       "      <td>360789</td>\n",
       "      <td>Source1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Object2</td>\n",
       "      <td>Property3</td>\n",
       "      <td>217264</td>\n",
       "      <td>Source1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Object3</td>\n",
       "      <td>Property5</td>\n",
       "      <td>274376</td>\n",
       "      <td>Source1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>Object996</td>\n",
       "      <td>Property1</td>\n",
       "      <td>978533</td>\n",
       "      <td>Source8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>Object997</td>\n",
       "      <td>Property1</td>\n",
       "      <td>591492</td>\n",
       "      <td>Source8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>Object998</td>\n",
       "      <td>Property1</td>\n",
       "      <td>542462</td>\n",
       "      <td>Source8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>Object999</td>\n",
       "      <td>Property1</td>\n",
       "      <td>983588</td>\n",
       "      <td>Source8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>Object1000</td>\n",
       "      <td>Property1</td>\n",
       "      <td>964731</td>\n",
       "      <td>Source8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Object   Property   Value   Source\n",
       "0         Object1  Property5  234041  Source1\n",
       "1         Object1  Property3  476627  Source1\n",
       "2         Object2  Property5  360789  Source1\n",
       "3         Object2  Property3  217264  Source1\n",
       "4         Object3  Property5  274376  Source1\n",
       "...           ...        ...     ...      ...\n",
       "59995   Object996  Property1  978533  Source8\n",
       "59996   Object997  Property1  591492  Source8\n",
       "59997   Object998  Property1  542462  Source8\n",
       "59998   Object999  Property1  983588  Source8\n",
       "59999  Object1000  Property1  964731  Source8\n",
       "\n",
       "[60000 rows x 4 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "1787fd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_.to_csv('/Users/admin/Documents/my thesis/My_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "df0e1613",
   "metadata": {},
   "outputs": [],
   "source": [
    "My_data=pd.read_csv('My_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "a3fb7c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Object</th>\n",
       "      <th>Property</th>\n",
       "      <th>Value</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Object1</td>\n",
       "      <td>Property5</td>\n",
       "      <td>234041</td>\n",
       "      <td>Source1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Object1</td>\n",
       "      <td>Property3</td>\n",
       "      <td>476627</td>\n",
       "      <td>Source1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Object2</td>\n",
       "      <td>Property5</td>\n",
       "      <td>360789</td>\n",
       "      <td>Source1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Object2</td>\n",
       "      <td>Property3</td>\n",
       "      <td>217264</td>\n",
       "      <td>Source1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Object3</td>\n",
       "      <td>Property5</td>\n",
       "      <td>274376</td>\n",
       "      <td>Source1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>Object996</td>\n",
       "      <td>Property1</td>\n",
       "      <td>978533</td>\n",
       "      <td>Source8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>Object997</td>\n",
       "      <td>Property1</td>\n",
       "      <td>591492</td>\n",
       "      <td>Source8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>Object998</td>\n",
       "      <td>Property1</td>\n",
       "      <td>542462</td>\n",
       "      <td>Source8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>Object999</td>\n",
       "      <td>Property1</td>\n",
       "      <td>983588</td>\n",
       "      <td>Source8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>Object1000</td>\n",
       "      <td>Property1</td>\n",
       "      <td>964731</td>\n",
       "      <td>Source8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Object   Property   Value   Source\n",
       "0         Object1  Property5  234041  Source1\n",
       "1         Object1  Property3  476627  Source1\n",
       "2         Object2  Property5  360789  Source1\n",
       "3         Object2  Property3  217264  Source1\n",
       "4         Object3  Property5  274376  Source1\n",
       "...           ...        ...     ...      ...\n",
       "59995   Object996  Property1  978533  Source8\n",
       "59996   Object997  Property1  591492  Source8\n",
       "59997   Object998  Property1  542462  Source8\n",
       "59998   Object999  Property1  983588  Source8\n",
       "59999  Object1000  Property1  964731  Source8\n",
       "\n",
       "[60000 rows x 4 columns]"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "My_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "c687da21",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_ = sc.textFile(\"My_data.csv\")\n",
    "essai=read_.map(lambda line: line.split(\",\")).map(lambda line:(line[0],line[1],line[2],line[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "f6d6f5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Object', 'Property', 'Value', 'Source'),\n",
       " ('Object1', 'Property5', '234041', 'Source1'),\n",
       " ('Object1', 'Property3', '476627', 'Source1'),\n",
       " ('Object2', 'Property5', '360789', 'Source1'),\n",
       " ('Object2', 'Property3', '217264', 'Source1'),\n",
       " ('Object3', 'Property5', '274376', 'Source1'),\n",
       " ('Object3', 'Property3', '293465', 'Source1'),\n",
       " ('Object4', 'Property5', '223567', 'Source1'),\n",
       " ('Object4', 'Property3', '278921', 'Source1'),\n",
       " ('Object5', 'Property5', '382661', 'Source1')]"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essai.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "a9cd3711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# essai.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63191843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f955d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "221fbb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapfonction(x):\n",
    "    return ((x[0],x[1],x[2]),-ln(1-x[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "734ea5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduceFonction(x,y):\n",
    "    return x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "9175bb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=essai.map(mapfonction).reduceByKey(reduceFonction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "68532d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.saveAsTextFile(\"data_Res.csv/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64db9f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallelisation de truthfinder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d30d0eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallelisation de la fonction de confidence d'une valeur "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "31ea4b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constitution de dataframe pour le travail\n",
    "My_data['TSInitial']=0.8\n",
    "My_data['C_v']=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "80fef140",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "My_data.to_csv('/Users/admin/Documents/my thesis/data_T.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "77d40bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_T=pd.read_csv( 'data_T.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "bc2e9755",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Object</th>\n",
       "      <th>Property</th>\n",
       "      <th>Value</th>\n",
       "      <th>Source</th>\n",
       "      <th>TSInitial</th>\n",
       "      <th>C_v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Object1</td>\n",
       "      <td>Property5</td>\n",
       "      <td>234041</td>\n",
       "      <td>Source1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Object1</td>\n",
       "      <td>Property3</td>\n",
       "      <td>476627</td>\n",
       "      <td>Source1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Object2</td>\n",
       "      <td>Property5</td>\n",
       "      <td>360789</td>\n",
       "      <td>Source1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Object2</td>\n",
       "      <td>Property3</td>\n",
       "      <td>217264</td>\n",
       "      <td>Source1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Object3</td>\n",
       "      <td>Property5</td>\n",
       "      <td>274376</td>\n",
       "      <td>Source1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>Object996</td>\n",
       "      <td>Property1</td>\n",
       "      <td>978533</td>\n",
       "      <td>Source8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>Object997</td>\n",
       "      <td>Property1</td>\n",
       "      <td>591492</td>\n",
       "      <td>Source8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>Object998</td>\n",
       "      <td>Property1</td>\n",
       "      <td>542462</td>\n",
       "      <td>Source8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>Object999</td>\n",
       "      <td>Property1</td>\n",
       "      <td>983588</td>\n",
       "      <td>Source8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>Object1000</td>\n",
       "      <td>Property1</td>\n",
       "      <td>964731</td>\n",
       "      <td>Source8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Object   Property   Value   Source  TSInitial  C_v\n",
       "0         Object1  Property5  234041  Source1        0.8  0.0\n",
       "1         Object1  Property3  476627  Source1        0.8  0.0\n",
       "2         Object2  Property5  360789  Source1        0.8  0.0\n",
       "3         Object2  Property3  217264  Source1        0.8  0.0\n",
       "4         Object3  Property5  274376  Source1        0.8  0.0\n",
       "...           ...        ...     ...      ...        ...  ...\n",
       "59995   Object996  Property1  978533  Source8        0.8  0.0\n",
       "59996   Object997  Property1  591492  Source8        0.8  0.0\n",
       "59997   Object998  Property1  542462  Source8        0.8  0.0\n",
       "59998   Object999  Property1  983588  Source8        0.8  0.0\n",
       "59999  Object1000  Property1  964731  Source8        0.8  0.0\n",
       "\n",
       "[60000 rows x 6 columns]"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "1e707fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_T['C_v']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "id": "741cda59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition de la matice de similarite\n",
    "def similarity(dataframe):\n",
    "    dict_sim = {}\n",
    "    for key, df in dataframe.groupby(by=['Object','Property']):\n",
    "        Values = df['Value'].unique()\n",
    "        row = key[0]+key[1]\n",
    "        for  i in range(len(Values)):\n",
    "            w1 = Values[i]\n",
    "            for  u in range(len(Values)):\n",
    "                w2 = Values[u]\n",
    "                sim = 1\n",
    "                if w1!=w2:\n",
    "                    t = abs(w1-w2)\n",
    "                    sim = 1/t\n",
    "                dict_sim[row+str(w1)+str(w2)] = sim\n",
    "                dict_sim[row+str(w2)+str(w1)] = sim\n",
    "    return dict_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "id": "2cda6ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition des fonctions globales de l'algorithme\n",
    "global rho\n",
    "rho=0.7\n",
    "global lam\n",
    "lam=0.5\n",
    "global dict_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05c87ee",
   "metadata": {},
   "source": [
    "Fonction de confiance d'une source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "8b73c91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertissons notre dataFrame en RDD\n",
    "read_ = sc.textFile(\"data_T.csv\")\n",
    "# Spliter selon les lignes de notre dataFrame\n",
    "read_rdd=read_.map(lambda line: line.split(\",\")).map(lambda line:(line[0],line[1],line[2],line[3],line[4],line[5])).filter(lambda x: x[0]!='Object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "c7458a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Object1', 'Property5', '234041', 'Source1', '0.8', '0.0'),\n",
       " ('Object1', 'Property3', '476627', 'Source1', '0.8', '0.0'),\n",
       " ('Object2', 'Property5', '360789', 'Source1', '0.8', '0.0'),\n",
       " ('Object2', 'Property3', '217264', 'Source1', '0.8', '0.0'),\n",
       " ('Object3', 'Property5', '274376', 'Source1', '0.8', '0.0')]"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lecture de notre RDD\n",
    "read_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "723e031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "b393b6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# la fonction Map\n",
    "# (input x est un quatriplet constitutue de (object,property,valeur, TSinitial) et le renvoie \n",
    "# la cle(object,property,valeur) et la valeur sigma_v)\n",
    "def MapFunction(x):\n",
    "    return ((x[0],x[1],x[2]),-m.log(1-float(x[4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "f136986e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Object1', 'Property5', '234041'), 1.6094379124341005),\n",
       " (('Object1', 'Property3', '476627'), 1.6094379124341005)]"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# la sortie de la fonction Map\n",
    "retourMap=read_rdd.map(MapFunction)\n",
    "retourMap.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694dfe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retour=read.map(MapFunction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "1cfc51dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition de la fonction reduce\n",
    "# la fonction reduce prend en entree x qui est la cle et Y qui est de valeur dans le output du map\n",
    "def ReduceFunction(x,y):\n",
    "    return x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "id": "bd0f1509",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/spark-3.0.3/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "/Users/admin/spark-3.0.3/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('Object1', 'Property3', '476627'), 4.8283137373023015),\n",
       " (('Object2', 'Property3', '217264'), 4.8283137373023015)]"
      ]
     },
     "execution_count": 759,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retourMap.reduceByKey(ReduceFunction).take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "a32f094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output=read_rdd.map(MapFunction)\n",
    "output=read_rdd.map(MapFunction).reduceByKey(ReduceFunction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "86850622",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Object1', 'Property3', '476627'), 4.8283137373023015),\n",
       " (('Object2', 'Property3', '217264'), 4.8283137373023015),\n",
       " (('Object3', 'Property5', '274376'), 4.8283137373023015),\n",
       " (('Object3', 'Property3', '293465'), 4.8283137373023015),\n",
       " (('Object4', 'Property5', '223567'), 4.8283137373023015),\n",
       " (('Object4', 'Property3', '278921'), 4.8283137373023015),\n",
       " (('Object7', 'Property3', '160372'), 4.8283137373023015),\n",
       " (('Object8', 'Property3', '345722'), 4.8283137373023015),\n",
       " (('Object9', 'Property5', '387265'), 4.8283137373023015),\n",
       " (('Object10', 'Property5', '363700'), 4.8283137373023015)]"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "5a358f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output.take(100).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "id": "6f271341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def maps(x):\n",
    "#     X=(x[0][0],x[0][1]),[(x[0][2],x[1])]\n",
    "#     Z=X[0]\n",
    "#     Y=X[1]\n",
    "#     for i in X[0]:\n",
    "#         lis=[]\n",
    "#         for j in X[0]:\n",
    "#             if i==j:\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "id": "924aea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output.map(essai).take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5ceb85",
   "metadata": {},
   "source": [
    "Debut de la fonction ajustement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "id": "964163ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Object1', 'Property3', '476627'), 4.8283137373023015),\n",
       " (('Object2', 'Property3', '217264'), 4.8283137373023015),\n",
       " (('Object3', 'Property5', '274376'), 4.8283137373023015),\n",
       " (('Object3', 'Property3', '293465'), 4.8283137373023015)]"
      ]
     },
     "execution_count": 830,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "id": "274dba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mapelement(x):\n",
    "    return (x[0][0],x[0][1]),[(x[0][2],x[1])]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "id": "aff642b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReduceShuffling(x,y):\n",
    "    return x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "id": "3e458afc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transf=output.map(Mapelement)#.reduceByKey(ReduceShuffling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "id": "075333bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Object1', 'Property3'), [('476627', 4.8283137373023015)]),\n",
       " (('Object2', 'Property3'), [('217264', 4.8283137373023015)]),\n",
       " (('Object3', 'Property5'), [('274376', 4.8283137373023015)]),\n",
       " (('Object3', 'Property3'), [('293465', 4.8283137373023015)]),\n",
       " (('Object4', 'Property5'), [('223567', 4.8283137373023015)])]"
      ]
     },
     "execution_count": 985,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transf.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "id": "3f0afc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Object', 'Property'): 0}"
      ]
     },
     "execution_count": 929,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = {}\n",
    "dic[('Object', 'Property')] = 0\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "id": "0fb35b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def someFunction(items, props):\n",
    "    df = {}\n",
    "    val = []\n",
    "    for item in items:\n",
    "        if item[0] == props:\n",
    "            val.append(item[1][0])\n",
    "    df[props] = val\n",
    "    val = []\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "id": "4c67d02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = transf.take(6000)\n",
    "f = [transf.take(60)[i][0] for i in range(60)]\n",
    "dff = []\n",
    "for props in f:\n",
    "    dff.append(someFunction(items, props))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "id": "06266409",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{('Object1', 'Property3'): [('476627', 4.8283137373023015),\n",
       "   ('614710', 3.218875824868201),\n",
       "   ('921796', 1.6094379124341005),\n",
       "   ('940859', 1.6094379124341005)]},\n",
       " {('Object2', 'Property3'): [('217264', 4.8283137373023015),\n",
       "   ('503996', 3.218875824868201),\n",
       "   ('702571', 1.6094379124341005),\n",
       "   ('573432', 1.6094379124341005)]},\n",
       " {('Object3', 'Property5'): [('274376', 4.8283137373023015),\n",
       "   ('623856', 1.6094379124341005)]},\n",
       " {('Object3', 'Property3'): [('293465', 4.8283137373023015),\n",
       "   ('939948', 3.218875824868201),\n",
       "   ('780181', 3.218875824868201)]},\n",
       " {('Object4', 'Property5'): [('223567', 4.8283137373023015),\n",
       "   ('648988', 1.6094379124341005)]},\n",
       " {('Object4', 'Property3'): [('278921', 4.8283137373023015),\n",
       "   ('795386', 1.6094379124341005),\n",
       "   ('657001', 6.437751649736402),\n",
       "   ('917567', 1.6094379124341005)]},\n",
       " {('Object7', 'Property3'): [('160372', 4.8283137373023015),\n",
       "   ('687519', 3.218875824868201),\n",
       "   ('721216', 1.6094379124341005)]},\n",
       " {('Object8', 'Property3'): [('345722', 4.8283137373023015),\n",
       "   ('568556', 1.6094379124341005),\n",
       "   ('661359', 1.6094379124341005),\n",
       "   ('729759', 1.6094379124341005)]},\n",
       " {('Object9', 'Property5'): [('387265', 4.8283137373023015),\n",
       "   ('606678', 1.6094379124341005),\n",
       "   ('849857', 1.6094379124341005),\n",
       "   ('595647', 3.218875824868201),\n",
       "   ('980890', 1.6094379124341005),\n",
       "   ('895644', 3.218875824868201)]},\n",
       " {('Object10', 'Property5'): [('363700', 4.8283137373023015),\n",
       "   ('744914', 1.6094379124341005)]},\n",
       " {('Object10', 'Property3'): [('144407', 4.8283137373023015),\n",
       "   ('666387', 4.8283137373023015),\n",
       "   ('923781', 1.6094379124341005),\n",
       "   ('677372', 1.6094379124341005)]},\n",
       " {('Object15', 'Property5'): [('476851', 4.8283137373023015),\n",
       "   ('620754', 1.6094379124341005),\n",
       "   ('827488', 1.6094379124341005),\n",
       "   ('515990', 3.218875824868201)]},\n",
       " {('Object16', 'Property5'): [('299348', 4.8283137373023015),\n",
       "   ('672838', 1.6094379124341005),\n",
       "   ('926207', 1.6094379124341005),\n",
       "   ('563669', 3.218875824868201)]},\n",
       " {('Object16', 'Property3'): [('206043', 4.8283137373023015),\n",
       "   ('666632', 1.6094379124341005)]},\n",
       " {('Object17', 'Property5'): [('374795', 4.8283137373023015),\n",
       "   ('930333', 4.8283137373023015),\n",
       "   ('823964', 1.6094379124341005),\n",
       "   ('613070', 3.218875824868201)]},\n",
       " {('Object17', 'Property3'): [('256275', 4.8283137373023015),\n",
       "   ('906880', 3.218875824868201)]},\n",
       " {('Object19', 'Property5'): [('368104', 4.8283137373023015),\n",
       "   ('810167', 3.218875824868201),\n",
       "   ('753119', 1.6094379124341005),\n",
       "   ('546114', 3.218875824868201),\n",
       "   ('505083', 1.6094379124341005)]},\n",
       " {('Object19', 'Property3'): [('305918', 4.8283137373023015),\n",
       "   ('567259', 1.6094379124341005),\n",
       "   ('620527', 1.6094379124341005),\n",
       "   ('656445', 1.6094379124341005),\n",
       "   ('732084', 1.6094379124341005)]},\n",
       " {('Object20', 'Property3'): [('471219', 4.8283137373023015),\n",
       "   ('557344', 1.6094379124341005),\n",
       "   ('821290', 1.6094379124341005),\n",
       "   ('944641', 3.218875824868201),\n",
       "   ('534934', 1.6094379124341005),\n",
       "   ('924460', 1.6094379124341005),\n",
       "   ('581109', 1.6094379124341005)]},\n",
       " {('Object21', 'Property5'): [('148088', 4.8283137373023015),\n",
       "   ('676574', 3.218875824868201)]},\n",
       " {('Object22', 'Property5'): [('187280', 4.8283137373023015),\n",
       "   ('999416', 3.218875824868201),\n",
       "   ('740409', 1.6094379124341005)]},\n",
       " {('Object23', 'Property3'): [('104051', 4.8283137373023015),\n",
       "   ('537954', 1.6094379124341005),\n",
       "   ('849844', 1.6094379124341005),\n",
       "   ('896437', 3.218875824868201),\n",
       "   ('606112', 1.6094379124341005)]},\n",
       " {('Object24', 'Property5'): [('210584', 4.8283137373023015),\n",
       "   ('689910', 1.6094379124341005)]},\n",
       " {('Object25', 'Property5'): [('294092', 4.8283137373023015),\n",
       "   ('675780', 1.6094379124341005),\n",
       "   ('638152', 3.218875824868201)]},\n",
       " {('Object25', 'Property3'): [('131822', 4.8283137373023015),\n",
       "   ('638225', 1.6094379124341005)]},\n",
       " {('Object28', 'Property3'): [('449582', 4.8283137373023015),\n",
       "   ('683786', 1.6094379124341005)]},\n",
       " {('Object30', 'Property5'): [('451200', 4.8283137373023015),\n",
       "   ('731306', 3.218875824868201),\n",
       "   ('837573', 1.6094379124341005),\n",
       "   ('656801', 1.6094379124341005),\n",
       "   ('563175', 1.6094379124341005),\n",
       "   ('779386', 3.218875824868201)]},\n",
       " {('Object34', 'Property5'): [('463697', 4.8283137373023015),\n",
       "   ('671888', 4.8283137373023015),\n",
       "   ('986703', 3.218875824868201)]},\n",
       " {('Object36', 'Property3'): [('116930', 4.8283137373023015),\n",
       "   ('968556', 3.218875824868201),\n",
       "   ('720831', 1.6094379124341005),\n",
       "   ('717140', 1.6094379124341005)]},\n",
       " {('Object39', 'Property3'): [('187266', 4.8283137373023015),\n",
       "   ('521143', 3.218875824868201),\n",
       "   ('957731', 1.6094379124341005),\n",
       "   ('566119', 1.6094379124341005)]},\n",
       " {('Object41', 'Property5'): [('121564', 4.8283137373023015),\n",
       "   ('509339', 1.6094379124341005),\n",
       "   ('597238', 1.6094379124341005)]},\n",
       " {('Object41', 'Property3'): [('457985', 4.8283137373023015),\n",
       "   ('775732', 1.6094379124341005),\n",
       "   ('781951', 1.6094379124341005)]},\n",
       " {('Object44', 'Property5'): [('311372', 4.8283137373023015),\n",
       "   ('773488', 3.218875824868201),\n",
       "   ('680225', 1.6094379124341005),\n",
       "   ('934767', 3.218875824868201)]},\n",
       " {('Object44', 'Property3'): [('375537', 4.8283137373023015),\n",
       "   ('737078', 1.6094379124341005),\n",
       "   ('509656', 1.6094379124341005)]},\n",
       " {('Object45', 'Property3'): [('428376', 4.8283137373023015),\n",
       "   ('786582', 1.6094379124341005),\n",
       "   ('842688', 1.6094379124341005)]},\n",
       " {('Object46', 'Property3'): [('254406', 4.8283137373023015),\n",
       "   ('848406', 1.6094379124341005),\n",
       "   ('869928', 1.6094379124341005),\n",
       "   ('644043', 1.6094379124341005)]},\n",
       " {('Object47', 'Property5'): [('345683', 4.8283137373023015),\n",
       "   ('926194', 1.6094379124341005),\n",
       "   ('616463', 3.218875824868201),\n",
       "   ('950495', 1.6094379124341005)]},\n",
       " {('Object47', 'Property3'): [('455243', 4.8283137373023015),\n",
       "   ('880072', 3.218875824868201),\n",
       "   ('560387', 1.6094379124341005),\n",
       "   ('716386', 1.6094379124341005)]},\n",
       " {('Object48', 'Property5'): [('351712', 4.8283137373023015),\n",
       "   ('649367', 3.218875824868201),\n",
       "   ('725752', 1.6094379124341005),\n",
       "   ('955729', 1.6094379124341005)]},\n",
       " {('Object48', 'Property3'): [('233116', 4.8283137373023015),\n",
       "   ('921980', 3.218875824868201),\n",
       "   ('986763', 1.6094379124341005)]},\n",
       " {('Object49', 'Property5'): [('153601', 4.8283137373023015),\n",
       "   ('720215', 1.6094379124341005),\n",
       "   ('678688', 3.218875824868201)]},\n",
       " {('Object49', 'Property3'): [('104563', 4.8283137373023015),\n",
       "   ('641613', 1.6094379124341005),\n",
       "   ('709200', 1.6094379124341005),\n",
       "   ('716504', 1.6094379124341005),\n",
       "   ('911818', 3.218875824868201),\n",
       "   ('647055', 1.6094379124341005)]},\n",
       " {('Object50', 'Property3'): [('464290', 4.8283137373023015),\n",
       "   ('779512', 1.6094379124341005),\n",
       "   ('910236', 4.8283137373023015),\n",
       "   ('725385', 1.6094379124341005)]},\n",
       " {('Object51', 'Property5'): [('178443', 4.8283137373023015)]},\n",
       " {('Object52', 'Property5'): [('267959', 4.8283137373023015),\n",
       "   ('658157', 3.218875824868201),\n",
       "   ('903112', 1.6094379124341005),\n",
       "   ('563663', 1.6094379124341005),\n",
       "   ('838817', 1.6094379124341005)]},\n",
       " {('Object52', 'Property3'): [('391524', 4.8283137373023015),\n",
       "   ('814578', 3.218875824868201),\n",
       "   ('615414', 1.6094379124341005),\n",
       "   ('870711', 1.6094379124341005),\n",
       "   ('553252', 1.6094379124341005),\n",
       "   ('589226', 1.6094379124341005)]},\n",
       " {('Object53', 'Property5'): [('277624', 4.8283137373023015),\n",
       "   ('543343', 3.218875824868201)]},\n",
       " {('Object54', 'Property3'): [('480868', 4.8283137373023015),\n",
       "   ('779839', 1.6094379124341005)]},\n",
       " {('Object55', 'Property5'): [('399349', 4.8283137373023015),\n",
       "   ('721868', 1.6094379124341005)]},\n",
       " {('Object56', 'Property5'): [('108421', 4.8283137373023015),\n",
       "   ('547755', 1.6094379124341005),\n",
       "   ('632202', 1.6094379124341005)]},\n",
       " {('Object59', 'Property5'): [('111415', 4.8283137373023015),\n",
       "   ('855017', 1.6094379124341005),\n",
       "   ('547542', 3.218875824868201),\n",
       "   ('871916', 1.6094379124341005)]},\n",
       " {('Object60', 'Property5'): [('107420', 4.8283137373023015),\n",
       "   ('707495', 1.6094379124341005),\n",
       "   ('938406', 1.6094379124341005)]},\n",
       " {('Object60', 'Property3'): [('476602', 4.8283137373023015),\n",
       "   ('606852', 1.6094379124341005),\n",
       "   ('889369', 3.218875824868201),\n",
       "   ('958345', 1.6094379124341005)]},\n",
       " {('Object62', 'Property3'): [('371738', 4.8283137373023015),\n",
       "   ('674892', 3.218875824868201),\n",
       "   ('750866', 1.6094379124341005),\n",
       "   ('584813', 1.6094379124341005)]},\n",
       " {('Object63', 'Property3'): [('245878', 4.8283137373023015),\n",
       "   ('575923', 3.218875824868201),\n",
       "   ('850588', 3.218875824868201),\n",
       "   ('665170', 4.8283137373023015)]},\n",
       " {('Object67', 'Property3'): [('106101', 4.8283137373023015),\n",
       "   ('977687', 3.218875824868201),\n",
       "   ('908336', 1.6094379124341005)]},\n",
       " {('Object68', 'Property5'): [('200750', 4.8283137373023015),\n",
       "   ('751894', 3.218875824868201),\n",
       "   ('707048', 3.218875824868201),\n",
       "   ('886851', 1.6094379124341005)]},\n",
       " {('Object72', 'Property5'): [('210817', 4.8283137373023015),\n",
       "   ('763393', 1.6094379124341005),\n",
       "   ('811124', 1.6094379124341005),\n",
       "   ('559253', 1.6094379124341005),\n",
       "   ('698658', 3.218875824868201)]},\n",
       " {('Object73', 'Property5'): [('286763', 4.8283137373023015),\n",
       "   ('734388', 1.6094379124341005),\n",
       "   ('729400', 1.6094379124341005),\n",
       "   ('855980', 1.6094379124341005)]},\n",
       " {('Object75', 'Property5'): [('283044', 4.8283137373023015),\n",
       "   ('742547', 1.6094379124341005),\n",
       "   ('939062', 1.6094379124341005),\n",
       "   ('535675', 1.6094379124341005)]}]"
      ]
     },
     "execution_count": 1013,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "id": "6f1327d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Object1', 'Property3'),\n",
       " ('Object2', 'Property3'),\n",
       " ('Object3', 'Property5'),\n",
       " ('Object3', 'Property3'),\n",
       " ('Object4', 'Property5'),\n",
       " ('Object4', 'Property3'),\n",
       " ('Object7', 'Property3'),\n",
       " ('Object8', 'Property3'),\n",
       " ('Object9', 'Property5'),\n",
       " ('Object10', 'Property5')]"
      ]
     },
     "execution_count": 994,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415f2ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.map(Mapelement).map(reduceFonction).reduceByKey(ReduceShuffling).take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "id": "2f19d865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Object1', 'Property3'): []}"
      ]
     },
     "execution_count": 884,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "id": "50a0b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduceFonction(x):\n",
    "    out=(x[0],[])\n",
    "    for v in x[1]:\n",
    "        c_v=v[1]\n",
    "        l=0\n",
    "        for v_ in x[1]:\n",
    "            if v[0]!=v_[0]:\n",
    "                Key_sim=x[0][0]+x[0][1]+str(v[0])+str(v_[0])\n",
    "                c_v+=rho*(v_[1]*dict_sim[Key_sim])\n",
    "        \n",
    "        CV=1/(1+np.exp(-lam*c_v))\n",
    "        out[1].append((v[0],CV))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "id": "5a766638",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/spark-3.0.3/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('Object1', 'Property3'),\n",
       "  [('476627', 4.8283137373023015),\n",
       "   ('614710', 3.218875824868201),\n",
       "   ('921796', 1.6094379124341005),\n",
       "   ('940859', 1.6094379124341005),\n",
       "   ('568214', 1.6094379124341005),\n",
       "   ('979204', 1.6094379124341005),\n",
       "   ('583144', 1.6094379124341005)])]"
      ]
     },
     "execution_count": 849,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transf.reduceByKey(reduceFonction).take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "id": "24c34522",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Object1', 'Property3'),\n",
       "  [('476627', 0.9179004847782343),\n",
       "   ('614710', 0.8333333333333334),\n",
       "   ('921796', 0.6909830056250527),\n",
       "   ('940859', 0.6909830056250527),\n",
       "   ('568214', 0.6909830056250527),\n",
       "   ('979204', 0.6909830056250527),\n",
       "   ('583144', 0.6909830056250527)]),\n",
       " (('Object2', 'Property3'),\n",
       "  [('217264', 0.9179004847782343),\n",
       "   ('503996', 0.8333333333333334),\n",
       "   ('702571', 0.6909830056250527),\n",
       "   ('573432', 0.6909830056250527),\n",
       "   ('738270', 0.6909830056250527),\n",
       "   ('992156', 0.6909830056250527),\n",
       "   ('798250', 0.6909830056250527)]),\n",
       " (('Object3', 'Property5'),\n",
       "  [('274376', 0.9179004847782343),\n",
       "   ('623856', 0.6909830056250527),\n",
       "   ('858686', 0.6909830056250527),\n",
       "   ('862053', 0.8333333333333334),\n",
       "   ('639971', 0.6909830056250527),\n",
       "   ('779628', 0.6909830056250527),\n",
       "   ('958810', 0.6909830056250527)])]"
      ]
     },
     "execution_count": 855,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.map(Mapelement).map(reduceFonction).reduceByKey(ReduceShuffling).take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "id": "ea53a9c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Object1', 'Property3'),\n",
       "  [('476627', 0.9179022328966988),\n",
       "   ('614710', 0.8333399034562446),\n",
       "   ('921796', 0.6909936995519688),\n",
       "   ('940859', 0.6909946257355961),\n",
       "   ('568214', 0.6910011307820197),\n",
       "   ('979204', 0.6909902118314286),\n",
       "   ('583144', 0.6910030650579354)]),\n",
       " (('Object2', 'Property3'),\n",
       "  [('217264', 0.917901196851986),\n",
       "   ('503996', 0.8333364327146271),\n",
       "   ('702571', 0.6909909336584837),\n",
       "   ('573432', 0.690989966511498),\n",
       "   ('738270', 0.6909913030106378),\n",
       "   ('992156', 0.6909857607265718),\n",
       "   ('798250', 0.6909888619487258)]),\n",
       " (('Object3', 'Property5'),\n",
       "  [('274376', 0.9179010855120032),\n",
       "   ('623856', 0.6909941552053976),\n",
       "   ('858686', 0.6910588490365589),\n",
       "   ('862053', 0.8333594058834171),\n",
       "   ('639971', 0.6909943279603301),\n",
       "   ('779628', 0.6909904643557644),\n",
       "   ('958810', 0.6909886279370928)])]"
      ]
     },
     "execution_count": 858,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.map(Mapelement).reduceByKey(ReduceShuffling).map(reduceFonction).take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "id": "3f5bfaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sim=similarity(data_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "id": "9998869b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/14 18:22:26 ERROR Executor: Exception in task 0.0 in stage 514.0 (TID 355)\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/Users/admin/spark-3.0.3/python/lib/pyspark.zip/pyspark/worker.py\", line 605, in main\n",
      "    process()\n",
      "  File \"/Users/admin/spark-3.0.3/python/lib/pyspark.zip/pyspark/worker.py\", line 597, in process\n",
      "    serializer.dump_stream(out_iter, outfile)\n",
      "  File \"/Users/admin/spark-3.0.3/python/lib/pyspark.zip/pyspark/serializers.py\", line 271, in dump_stream\n",
      "    vs = list(itertools.islice(iterator, batch))\n",
      "  File \"/Users/admin/spark-3.0.3/python/pyspark/rdd.py\", line 928, in func\n",
      "    yield reduce(f, iterator, initial)\n",
      "  File \"/Users/admin/spark-3.0.3/python/pyspark/util.py\", line 107, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "TypeError: reduceFonction() takes 1 positional argument but 2 were given\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:503)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:638)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n",
      "\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\n",
      "\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\n",
      "\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\n",
      "\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1004)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2154)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:463)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:466)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "21/11/14 18:22:26 WARN TaskSetManager: Lost task 0.0 in stage 514.0 (TID 355, admins-mbp, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/Users/admin/spark-3.0.3/python/lib/pyspark.zip/pyspark/worker.py\", line 605, in main\n",
      "    process()\n",
      "  File \"/Users/admin/spark-3.0.3/python/lib/pyspark.zip/pyspark/worker.py\", line 597, in process\n",
      "    serializer.dump_stream(out_iter, outfile)\n",
      "  File \"/Users/admin/spark-3.0.3/python/lib/pyspark.zip/pyspark/serializers.py\", line 271, in dump_stream\n",
      "    vs = list(itertools.islice(iterator, batch))\n",
      "  File \"/Users/admin/spark-3.0.3/python/pyspark/rdd.py\", line 928, in func\n",
      "    yield reduce(f, iterator, initial)\n",
      "  File \"/Users/admin/spark-3.0.3/python/pyspark/util.py\", line 107, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "TypeError: reduceFonction() takes 1 positional argument but 2 were given\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:503)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:638)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n",
      "\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\n",
      "\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\n",
      "\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\n",
      "\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1004)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2154)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:463)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:466)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "21/11/14 18:22:26 ERROR TaskSetManager: Task 0 in stage 514.0 failed 1 times; aborting job\n",
      "21/11/14 18:22:26 WARN TaskSetManager: Lost task 1.0 in stage 514.0 (TID 356, admins-mbp, executor driver): TaskKilled (Stage cancelled)\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 514.0 failed 1 times, most recent failure: Lost task 0.0 in stage 514.0 (TID 355, admins-mbp, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/Users/admin/spark-3.0.3/python/lib/pyspark.zip/pyspark/worker.py\", line 605, in main\n    process()\n  File \"/Users/admin/spark-3.0.3/python/lib/pyspark.zip/pyspark/worker.py\", line 597, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/Users/admin/spark-3.0.3/python/lib/pyspark.zip/pyspark/serializers.py\", line 271, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/Users/admin/spark-3.0.3/python/pyspark/rdd.py\", line 928, in func\n    yield reduce(f, iterator, initial)\n  File \"/Users/admin/spark-3.0.3/python/pyspark/util.py\", line 107, in wrapper\n    return f(*args, **kwargs)\nTypeError: reduceFonction() takes 1 positional argument but 2 were given\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:503)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:638)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1004)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2154)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:463)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:466)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2008)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2007)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2007)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:973)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:973)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:973)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2239)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2188)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2177)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:775)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2135)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2154)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2179)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1004)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1003)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:168)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/Users/admin/spark-3.0.3/python/lib/pyspark.zip/pyspark/worker.py\", line 605, in main\n    process()\n  File \"/Users/admin/spark-3.0.3/python/lib/pyspark.zip/pyspark/worker.py\", line 597, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/Users/admin/spark-3.0.3/python/lib/pyspark.zip/pyspark/serializers.py\", line 271, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/Users/admin/spark-3.0.3/python/pyspark/rdd.py\", line 928, in func\n    yield reduce(f, iterator, initial)\n  File \"/Users/admin/spark-3.0.3/python/pyspark/util.py\", line 107, in wrapper\n    return f(*args, **kwargs)\nTypeError: reduceFonction() takes 1 positional argument but 2 were given\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:503)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:638)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1004)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2154)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:463)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:466)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jm/xsstn31d4jv8my30vph7dpl00000gn/T/ipykernel_1804/1959532641.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdonnee\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMapelement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduceByKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mReduceShuffling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduceFonction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/spark-3.0.3/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-3.0.3/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \"\"\"\n\u001b[1;32m    888\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-3.0.3/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-3.0.3/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 514.0 failed 1 times, most recent failure: Lost task 0.0 in stage 514.0 (TID 355, admins-mbp, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/Users/admin/spark-3.0.3/python/lib/pyspark.zip/pyspark/worker.py\", line 605, in main\n    process()\n  File \"/Users/admin/spark-3.0.3/python/lib/pyspark.zip/pyspark/worker.py\", line 597, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/Users/admin/spark-3.0.3/python/lib/pyspark.zip/pyspark/serializers.py\", line 271, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/Users/admin/spark-3.0.3/python/pyspark/rdd.py\", line 928, in func\n    yield reduce(f, iterator, initial)\n  File \"/Users/admin/spark-3.0.3/python/pyspark/util.py\", line 107, in wrapper\n    return f(*args, **kwargs)\nTypeError: reduceFonction() takes 1 positional argument but 2 were given\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:503)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:638)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1004)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2154)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:463)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:466)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2008)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2007)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2007)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:973)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:973)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:973)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2239)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2188)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2177)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:775)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2135)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2154)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2179)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1004)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1003)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:168)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/Users/admin/spark-3.0.3/python/lib/pyspark.zip/pyspark/worker.py\", line 605, in main\n    process()\n  File \"/Users/admin/spark-3.0.3/python/lib/pyspark.zip/pyspark/worker.py\", line 597, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/Users/admin/spark-3.0.3/python/lib/pyspark.zip/pyspark/serializers.py\", line 271, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/Users/admin/spark-3.0.3/python/pyspark/rdd.py\", line 928, in func\n    yield reduce(f, iterator, initial)\n  File \"/Users/admin/spark-3.0.3/python/pyspark/util.py\", line 107, in wrapper\n    return f(*args, **kwargs)\nTypeError: reduceFonction() takes 1 positional argument but 2 were given\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:503)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:638)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1004)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2154)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:463)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:466)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "donnee=output.map(Mapelement).reduceByKey(ReduceShuffling).reduce(reduceFonction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "60890ee9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Object1', 'Property3'),\n",
       "  [('476627', 0.858874901684857),\n",
       "   ('614710', 0.7692370510538484),\n",
       "   ('921796', 0.6461191986885603),\n",
       "   ('940859', 0.6461199406270961),\n",
       "   ('568214', 0.6461251516437867),\n",
       "   ('979204', 0.6461164047826595),\n",
       "   ('583144', 0.6461267011448922)]),\n",
       " (('Object2', 'Property3'),\n",
       "  [('217264', 0.8588736550867768),\n",
       "   ('503996', 0.7692337326001029),\n",
       "   ('702571', 0.6461169830155514),\n",
       "   ('573432', 0.6461162082646716),\n",
       "   ('738270', 0.6461172788920387),\n",
       "   ('992156', 0.6461128391499741),\n",
       "   ('798250', 0.64611532343505)])]"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donnee.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "5f32bdb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Object2', 'Property3'),\n",
       "  [('217264', 0.8588736550867768),\n",
       "   ('503996', 0.7692337326001029),\n",
       "   ('702571', 0.6461169830155514),\n",
       "   ('573432', 0.6461162082646716),\n",
       "   ('738270', 0.6461172788920387),\n",
       "   ('992156', 0.6461128391499741),\n",
       "   ('798250', 0.64611532343505)])]"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def fonc(donnee,objet,propert):\n",
    "#     return donnee.filter(lambda x:x[0]==('Object2','Property3'))\n",
    "list(donnee.filter(lambda x:x[0]==('Object2','Property3')).take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "b011ead8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/spark-3.0.3/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "/Users/admin/spark-3.0.3/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "global donne\n",
    "donne=dict(list(donnee.collect()))\n",
    "def MapFor(x):\n",
    "    T=donne[(x[0],x[1])]\n",
    "#     T=list(donne.filter(lambda V:V[0]==(x[0],x[1])).take(1))\n",
    "    \n",
    "    Y=T[0][1]\n",
    "    C_v=0\n",
    "    for v in Y:\n",
    "        if v[0]==x[2]:\n",
    "            C_v=v[1]\n",
    "            break\n",
    "            \n",
    "    return x[0],x[1],x[2],x[3],C_v    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "01b39809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MapFor(dict(list(donnee.collect())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "4e886672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "28a5bdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re=result.map(lambda x:x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "bf3cbb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "b9a71106",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MapFor(('Object1', 'Property5', '234041', 'Source1', '0.7'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "210f6a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Object1', 'Property5', '234041', 'Source1', '0.7')]"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "1047419f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_essai.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "40a8d8fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# col(df, 'B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "324fbf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_essai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "098d480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_fin=data_essai['C-v']=col(df, 'B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "2b4fe12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t=donnee.filter(lambda x:x[0]==('Object2','Property3'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "cb1b4ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/spark-3.0.3/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('Object2', 'Property3'),\n",
       "  [('217264', 0.8588736550867768),\n",
       "   ('503996', 0.7692337326001029),\n",
       "   ('702571', 0.6461169830155514),\n",
       "   ('573432', 0.6461162082646716),\n",
       "   ('738270', 0.6461172788920387),\n",
       "   ('992156', 0.6461128391499741),\n",
       "   ('798250', 0.64611532343505)])]"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4c4e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "key="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ffe548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7615ebc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
